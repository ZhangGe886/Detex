{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The DataFetcher\n",
    "The DataFetcher class is by detex to serve seismic data to other functions and classes. It is designed to use data from local directories as well as remote clients (like the [obspy FDSN client](https://docs.obspy.org/packages/obspy.fdsn.html)). In the future I hope to add functionality to the DataFetcher to allow it to check data availability and quality. We will start by looking at the DataFetcher class docs, using the DataFetcher on local data directories, and then setting up a DataFetcher to use a remote client. \n",
    "\n",
    "## DataFetcher docs\n",
    "Let's print the current version of detex and the docstring associated with the DataFetcher class in order to get an idea of what it does and what options are available.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detex\n",
    "print('Current detex version is %s' % (detex.__version__))\n",
    "print ('-------------------------------')\n",
    "print (detex.getdata.DataFetcher.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the more important parameters to pay attention to are the ones controlling the duration of files and the response removal. \n",
    "\n",
    "* Parameters that control data duration, number of files, and file type:\n",
    "\n",
    "    1. timeBeforeOrigin \n",
    "    \n",
    "    2. timeAfterOrigin \n",
    "    \n",
    "    3. conDatDuration \n",
    "    \n",
    "    4. secBuf \n",
    "    \n",
    "    \n",
    "* Parameters that control response removal (more on obspy response removal [here](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.remove_response.html#obspy.core.stream.Stream.remove_response))\n",
    "\n",
    "    1. removeResponse (True or False)\n",
    "    \n",
    "    2. opType (\"DISP\" (m), \"VEL\" (m/s), or \"ACC\" (m/s^2))\n",
    "    \n",
    "    3. prefilt \n",
    "\n",
    "\n",
    "Also, for less than perfect data, the fillZeros parameter can be very important to avoid discarding data with small gaps. More on this in the [clustering section](../Clustering/clustering.md). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFetcher with local directories\n",
    "Often it can be faster to download, preform some processing, and save data once rather than using clients each time detex needs seismic data. This is not always the case, however, if a database on the same network as your workstation is the remote client you wish to use. As an example, let's create a local data directory and then set up a DataFetcher instance to pull data from it. \n",
    "\n",
    "### Create local directories\n",
    "In order to create the data directories we first need to let Detex know which stations and events it should look for. To do this we use the template key and station key files (more on that in the [required files section](../RequiredFiles/required_files.md).\n",
    "\n",
    "For this example lets use a subset of the template key and station key used in the intro tutorial. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detex\n",
    "stakey = detex.util.readKey('StationKey.csv', key_type='station')\n",
    "stakey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temkey = detex.util.readKey('TemplateKey.csv', key_type='template')\n",
    "temkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to call makeDataDirectories (or getAllData which was kept for backward compatibility)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time detex.getdata.makeDataDirectories() # make directories and time how long it takes (the %time magic only works in ipython)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look at the downloaded data lets discuss some of the parameters that you should pay attention to when calling the makeDataDirectories function. You should notice that many of the makeDataDirectories function's input arguments are similar to DataFetchers arguments. This is because under the hood the makeDataDirectories function is simply using a DataFetcher attached to a client (IRIS by default). If you wanted to use something besides IRIS you would just need to pass a DataFetcher instance attached to another client as the fetch argument.\n",
    "\n",
    "One unique argument that makeDataDirectories needs is the formatOut, which is the format to use when saving the data to disk. Any format obspy can read/write should be acceptable. Options are: 'mseed', 'sac', 'GSE2', 'sacxy', 'q', 'sh_asc', 'slist', 'tspair', 'segy', 'su', 'pickle', 'h5' (if obspyh5 is installed). Default is mseed, although the makeDataDirectories call by default will remove instrument response thus necessitating that the data are in a float format and therefore devaluing the mseed compression advantage.\n",
    "\n",
    "I recommend you look at the entire doc string of the function, but I wont print it here. You should think about what parameters will work best for your data set before just using the defaults.\n",
    "\n",
    "Now let's take a look at the newly created data directories. This is most easily accomplished by reading the SQLite database that was created to index the directories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "index_file = os.path.join('ContinuousWaveForms', '.index.db')\n",
    "ind = detex.util.loadSQLite(index_file, 'ind')\n",
    "ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fields in the database table \"ind\" are as follows:\n",
    "\n",
    "| Field | Description |\n",
    "|:-----:| :---------: |\n",
    "| Path | A list of indicies to reference values in the indkey table for building absolute paths|\n",
    "| FileName | The name of the particular file represented by the current row |\n",
    "| Starttime | time stamp of the start time in the file |\n",
    "| Endtime | time stamp of the end time in the file |\n",
    "| Gaps | The total number of gaps in the file |\n",
    "| Nc | The number of unique channels |\n",
    "| Nt | The number of traces (without gaps Nc = Nt) |\n",
    "| Duration | Duration of seismic data in seconds |\n",
    "| Station | network.station |\n",
    "\n",
    "When the DataFetcher loads files from a directory it first reads the index to find the paths to load. Because of this, the directory structure not important. For example, if you already have a directory that contains some files in an obspy readable format you can index it with the detex.util.indexDirectory function. Once indexed the directory can be used by the DataFetcher class. \n",
    "\n",
    "It can be useful to use the index for data quality checks. For example, let's look for files that are shorter than expected, that are missing channels, or that have gaps (even though we can see these TA data don't have any such issues). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for gaps\n",
    "ind_gaps = ind[ind.Gaps > 0]\n",
    "print(\"There are %d files with gaps\" % len(ind_gaps))\n",
    "\n",
    "# Look for durations at least 2 minutes less than the expected duration\n",
    "expected_duration = 3720\n",
    "ind_short = ind[3720 - ind.Duration > 120]\n",
    "print(\"There are %d files with shorter than expected durations\" % len(ind_short))\n",
    "\n",
    "# look for missing channels\n",
    "expected_channels = 3\n",
    "ind_missing = ind[ind.Nc < expected_channels]\n",
    "print(\"There are %d files with less than %d channels\" % (len(ind_missing), expected_channels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Initiate DataFetcher\n",
    "Now we are ready to create a DataFetcher instance and point it at the newly created directory. We will also explore some of the DataFetcher methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two fetchers, one pointed at the continuous data and the other at the event data\n",
    "con_fetcher = detex.getdata.DataFetcher('dir', directoryName='ContinuousWaveForms', removeResponse=False)\n",
    "eve_fetcher = detex.getdata.DataFetcher('dir', directoryName='EventWaveForms', removeResponse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of version 1.0.4 the DataFetcher has 3 public methods:\n",
    "1. getStream - fetches an a stream from an arbitrary network, station, channel, location (which the user must define). If no data are fetchable then None is returned.\n",
    "2. getConData - creates a generator for fetching all data avaliable for the stations, channels, and date ranges found in a station key. \n",
    "3. getTemData - fetches data related to those described by the template key, but also needs a station key to know which stations to look for. \n",
    "Let's look at an example use of each method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getStream example\n",
    "import obspy\n",
    "\n",
    "## set variables\n",
    "utc1 = obspy.UTCDateTime('2009-091T04-13-00') - 5\n",
    "utc2 = utc1 + 60\n",
    "net = 'TA'\n",
    "sta = 'M17A'\n",
    "chan = 'BH?'\n",
    "\n",
    "## fetch\n",
    "st = con_fetcher.getStream(utc1, utc2, net, sta, chan)\n",
    "\n",
    "## plot the boring data\n",
    "%pylab inline \n",
    "st.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getConData example\n",
    "\n",
    "## Read station key and use only TA M17A\n",
    "\n",
    "stakey = detex.util.readKey('StationKey.csv', key_type='station')\n",
    "stakey = stakey[stakey.STATION=='M17A']\n",
    "\n",
    "## Create a generator for fetching continuous data\n",
    "congen = con_fetcher.getConData(stakey) # note if we dont pass a duration the default is used\n",
    "\n",
    "## loop over generator and calculate sta/lta values to see if we can find an event\n",
    "from obspy.signal.trigger import classicSTALTA # for simplicity let's use the basic sta/lta\n",
    "from obspy.signal.trigger import plotTrigger\n",
    "\n",
    "sta = 0.5 # short term average in seconds\n",
    "lta = 2 # long term average in seconds\n",
    "ratio_max = 0 # int variables to keep track of max and time it occurs\n",
    "time_max = 0\n",
    "trace_max = None\n",
    "cft_max = None\n",
    "\n",
    "for st in congen: # iterate through the generator until it is exhausted\n",
    "    trace = st.select(component = 'z')[0] # select vertical component\n",
    "    trace.filter('bandpass', freqmin=1, freqmax=10, zerophase=True, corners=2) #filter\n",
    "    sr = trace.stats.sampling_rate # get sampling rate\n",
    "    starttime = trace.stats.starttime\n",
    "    cft = classicSTALTA(trace.data, int(sta * sr), int(lta * sr)) # run sta/lta\n",
    "    cft_max = max(cft) # get max value\n",
    "    if cft_max > ratio_max: # if the max is greater than old max\n",
    "        ratio_max = cft_max # set new max\n",
    "        time_max = starttime + cft.argmax()/float(sr) # set time max\n",
    "        trace_max = trace.copy()\n",
    "        cft_max = cft\n",
    "\n",
    "print(\"The max sta/lta was %.2f occured at %s\" % (ratio_max, time_max))\n",
    "plotTrigger(trace, cft, ratio_max*.92, ratio_max/1.5)\n",
    "\n",
    "## Let's get a closer look\n",
    "\n",
    "st = con_fetcher.getStream(time_max-10, time_max+35, 'TA', 'M17A', 'BHZ')\n",
    "st.filter('bandpass', freqmin=1, freqmax=5, zerophase=True, corners=2)\n",
    "st.plot()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getConData example\n",
    "\n",
    "## Create stream generator\n",
    "evegen = eve_fetcher.getTemData(\"TemplateKey.csv\", \"StationKey.csv\")\n",
    "# note: the temkey and stakey parameters can either be paths to csv files or DataFrames\n",
    "\n",
    "## iterate through each of the known events plot a spectrogram of the one with highest amplitude\n",
    "amp_max = 0\n",
    "tr_max = None\n",
    "for st, evename in evegen:\n",
    "    trace = st.select(component = 'z')[0]\n",
    "    trace.detrend('linear')\n",
    "    trace.filter('bandpass', freqmin=1, freqmax=10, zerophase=True, corners=2)\n",
    "    z_max = max(trace.data)\n",
    "    if z_max > amp_max:\n",
    "        amp_max = z_max\n",
    "        tr_max = trace.copy()\n",
    "tr_max.plot()\n",
    "tr_max.spectrogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DataFetcher with clients\n",
    "Detex should be able to handle a wide variety of obspy client types, including FDSN, NEIC, EARTHWORM, etc. However, as of version 1.0.4 I have only tested IRIS extensively so using other clients may take a bit of debugging. More tests and bug fixes will follow in future versions. \n",
    "\n",
    "### IRIS FDSN client\n",
    "In order to use the DataFetcher we first need to set up a client object. We will create an FDSN client then initiate an instance of the DataFetcher class and use the getStream function to fetch an obspy stream. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detex\n",
    "import obspy\n",
    "from obspy.fdsn import Client\n",
    "\n",
    "#setup client\n",
    "client = Client(\"IRIS\")\n",
    "\n",
    "# setup fetcher\n",
    "fetcher = detex.getdata.DataFetcher(method='client', client=client)\n",
    "\n",
    "# set info\n",
    "utc1 = obspy.UTCDateTime('2009-03-19T19-06-07') - 5\n",
    "utc2 = utc1 + 60\n",
    "net = 'TA'\n",
    "sta = 'M17A'\n",
    "chan = 'BH?'\n",
    "\n",
    "# fetch a stream\n",
    "st = fetcher.getStream(utc1, utc2, net, sta, chan)\n",
    "\n",
    "# plot waveforms\n",
    "%pylab inline \n",
    "st.filter('bandpass', freqmin=1, freqmax=10, corners=2, zerophase=True)\n",
    "st.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the waveforms look strange it is because this event is actually a blast at a surface coal mine.\n",
    "\n",
    "The other methods demonstrated in previous sections also work with the DataFetcher attached to IRIS, so I wont illustrate them again here. \n",
    "\n",
    "It should be noted that by default the instrument responses have been removed. This can be controlled with the removeResponse input argument which is either set to True or False. \n",
    "\n",
    "This should give you all the information you need on how detex gets its data and how to set up a custom DataFetcher to be used by other detex classes. \n",
    "\n",
    "# Next Section\n",
    "The [next section](../Clustering/clustering.md) covers how to perform waveform similarity analysis in preparation for subspace detection. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
